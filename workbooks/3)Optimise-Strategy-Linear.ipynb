{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ea8743-367f-41ab-9650-c453fa313e0b",
   "metadata": {},
   "source": [
    "I think with the time frame my best approach is to use linear optimisation. It won't provide the highest output, but good enough for the sake of this exercise. The plan would be this: \n",
    "\n",
    "1) Change OfferAmt and optimise for the highest output of Spend\n",
    "2) Use Redemption Probability and median SpendPerCoupon£ to get the final spend values. \n",
    "\n",
    "REMEMBER: We can only offer an amout they have already been offered. The SUM of Coupons Redeemed cannot be more than £30,000\n",
    "\n",
    "__Dataset__\n",
    "\n",
    "Data needs to be filtered to include the target date week.\n",
    "\n",
    "- Gradient: Measure sensitiity to price increase of coupon.\n",
    "- Predicted_probaility: Probability they will take the coupon anount\n",
    "- Max: Max Coupon they have ever redeemed\n",
    "- Min: Min Coupon they have ever redeemed\n",
    "- SpendPerOfferAmtRedeemed: The median Spend per coupon recieved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "f9bf34e8-b00f-4cf8-8523-9524407f5da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8c369405-0e49-4a06-9e9d-3339c62fb45b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_training = pd.read_csv('../data/HistoricalTrainingData.csv')\n",
    "\n",
    "# Filter customers who visited the store in the last 90 days from 2019-07-01\n",
    "cutoff_date = pd.to_datetime('2019-07-01') - pd.Timedelta(days=90)\n",
    "df_recent_visitors = df_training[df_training['TripDate'] >= cutoff_date.strftime('%Y-%m-%d')]\n",
    "\n",
    "# Extract unique PatronIDs of recent visitors\n",
    "recent_visitor_ids = df_recent_visitors['PatronID'].unique()\n",
    "\n",
    "# Load customer prediction metrics and sensitivity metrics\n",
    "df_customer_prediction_metrics = pd.read_csv('./customer_prediction_metrics_nn.csv')\n",
    "df_customer_sensitivity_metrics = pd.read_csv('./customer_sensitivity_metrics.csv')\n",
    "\n",
    "df_customer_prediction_metrics['UseStartDate'] = pd.to_datetime(df_customer_prediction_metrics['UseStartDate'])\n",
    "df_customer_prediction_metrics = df_customer_prediction_metrics[df_customer_prediction_metrics[\"UseStartDate\"] == pd.to_datetime(\"2019-07-01\")]\n",
    "\n",
    "# Merge the two dataframes on PatronID\n",
    "df_merged_metrics = pd.merge(df_customer_prediction_metrics, df_customer_sensitivity_metrics, on='PatronID', how='inner')\n",
    "\n",
    "# Filter by the list of recent visitor PatronIDs\n",
    "data = df_merged_metrics[df_merged_metrics['PatronID'].isin(recent_visitor_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "bdf2e975-8598-411b-bf3d-7d260e848664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ratio of Spend to OfferAmtRedeemed for transactions where OfferAmtRedeemed > 0\n",
    "df_training['SpendPerOfferAmt'] = df_training.loc[df_training['OfferAmt'] > 0, 'Spend'] / df_training.loc[df_training['OfferAmt'] > 0, 'OfferAmt']\n",
    "\n",
    "\n",
    "# Calculate total visits by customer in the training data\n",
    "total_visits_by_customer = df_training.groupby('PatronID').size().reset_index(name='TotalVisits')\n",
    "\n",
    "# Calculate the median SpendPerOfferAmt for each customer\n",
    "median_spend_per_offer_amt_per_customer = df_training.groupby('PatronID')['SpendPerOfferAmt'].median().reset_index()\n",
    "median_spend_per_offer_amt_per_customer.rename(columns={'SpendPerOfferAmt': 'MedianSpendPerOfferAmt'}, inplace=True)\n",
    "\n",
    "# Calculate the maximum spend per individual in the training data\n",
    "max_spend_per_individual = df_training.groupby('PatronID')['Spend'].max().reset_index()\n",
    "max_spend_per_individual.rename(columns={'Spend': 'MaxSpendInTraining'}, inplace=True)\n",
    "\n",
    "# Calculate the median of the Spend to OfferAmtRedeemed ratio for each customer\n",
    "median_spend_per_offer_redeemed_per_customer = df_training.groupby('PatronID')['Spend'].median().reset_index()\n",
    "median_spend_per_offer_redeemed_per_customer.rename(columns={'Spend': 'MedianSpendInTraining'}, inplace=True)\n",
    "\n",
    "# Calculate the median of the Spend to OfferAmtRedeemed ratio for each customer\n",
    "min_spend_per_offer_redeemed_per_customer = df_training.groupby('PatronID')['Spend'].min().reset_index()\n",
    "min_spend_per_offer_redeemed_per_customer.rename(columns={'Spend': 'MinSpendInTraining'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the maximum and minimum OfferedAmt for each customer\n",
    "offer_ranges = df_training.groupby('PatronID')['OfferAmt'].agg(['max', 'min']).reset_index()\n",
    "offer_ranges.rename(columns={'max': 'MaxOfferAmt', 'min': 'MinOfferAmt'}, inplace=True)\n",
    "\n",
    "# Proceed with other merges as before\n",
    "optimisation_updated = data.merge(offer_ranges, on='PatronID', how='left')\\\n",
    "                            .merge(total_visits_by_customer, on='PatronID', how='left')\\\n",
    "                            .merge(max_spend_per_individual, on='PatronID', how='left')\\\n",
    "                            .merge(median_spend_per_offer_redeemed_per_customer, on='PatronID', how='left')\\\n",
    "                            .merge(min_spend_per_offer_redeemed_per_customer, on='PatronID', how='left')\n",
    "\n",
    "# Merge the median spend per offer amount redeemed with the optimization dataset\n",
    "optimised_data = optimisation_updated.merge(median_spend_per_offer_amt_per_customer, on='PatronID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d284fd56-8f3c-4942-873c-074fb4f82185",
   "metadata": {},
   "source": [
    "# Linear Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "6294d748-e6d5-4c32-bf01-3d4e027e91c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linprog\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "fd1729e2-e125-41ef-97fe-d16311d34a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimised_data['Spend'].fillna(0, inplace=True)\n",
    "optimised_data['OfferAmt'].fillna(0, inplace=True)\n",
    "optimised_data['OfferAmtRedeemed'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "0df34490-d55c-4391-931c-e7ffade3c8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization successful!\n",
      "Total Expected Spend: £74494.66\n",
      "Total Offer Amount: £30000.00\n",
      "ROI: 2.48\n"
     ]
    }
   ],
   "source": [
    "# Define a probability threshold\n",
    "PROBABILITY_THRESHOLD_LOW = 0.2 # min-median spend in training\n",
    "PROBABILITY_THRESHOLD_MED = 0.5 # The median spend in training\n",
    "PROBABILITY_THRESHOLD_HIGH = 0.6 # The median spend in training\n",
    "PROBABILITY_THRESHOLD_VHIGH = 0.7 # Max spend in training\n",
    "[InternetShortcut]\n",
    "URL=https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes\n",
    "\n",
    "# Preprocessing: Replace inf, NaN, or None values with the median for each column\n",
    "for column in optimised_data.columns:\n",
    "    if optimised_data[column].dtype in ['float64', 'int64']:\n",
    "        median_value =optimised_data[column].replace([np.inf, -np.inf], np.nan).median()\n",
    "        optimised_data[column].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        optimised_data[column].fillna(median_value, inplace=True)\n",
    "\n",
    "# Calculate maximum offer amount based on max historical spend\n",
    "optimised_data['MaxOfferBasedOnMaxSpend'] = optimised_data['MaxSpendInTraining'] / optimised_data['MedianSpendPerOfferAmt']\n",
    "\n",
    "# Adjust the bounds for the optimization problem\n",
    "bounds = []\n",
    "for index, row in optimised_data.iterrows():\n",
    "    # Set initial lower and upper bounds from MinOfferAmt and MaxOfferAmt\n",
    "    lower_bound, upper_bound = row['MinOfferAmt'], row['MaxOfferAmt']\n",
    "    \n",
    "    # Adjust the upper bound based on probability thresholds\n",
    "    if row['Predicted_Probability'] >= PROBABILITY_THRESHOLD_VHIGH:\n",
    "        upper_bound = min(upper_bound, row['MaxSpendInTraining'] / row['MedianSpendPerOfferAmt'])\n",
    "    elif row['Predicted_Probability'] >= PROBABILITY_THRESHOLD_HIGH:\n",
    "        # Set upper bound to not exceed a certain percentage of MaxSpendInTraining\n",
    "        upper_bound = min(upper_bound, 0.75 * row['MaxSpendInTraining'] / row['MedianSpendPerOfferAmt'])\n",
    "    elif row['Predicted_Probability'] >= PROBABILITY_THRESHOLD_MED:\n",
    "        # Further constrain the upper bound for medium probabilities\n",
    "        upper_bound = min(upper_bound, 0.5 * row['MaxSpendInTraining'] / row['MedianSpendPerOfferAmt'])\n",
    "    elif row['Predicted_Probability'] >= PROBABILITY_THRESHOLD_LOW:\n",
    "        # Only allow spending up to the median spend for the lowest tier\n",
    "        upper_bound = min(upper_bound, row['MedianSpendInTraining'] / row['MedianSpendPerOfferAmt'])\n",
    "    else:\n",
    "        # No offer for probabilities below the lowest threshold\n",
    "        lower_bound, upper_bound = 0, 0\n",
    "    \n",
    "    # Ensure lower bound does not exceed the new upper bound\n",
    "    if lower_bound > upper_bound:\n",
    "        adjusted_bound = (upper_bound, upper_bound)\n",
    "    else:\n",
    "        adjusted_bound = (lower_bound, upper_bound)\n",
    "    \n",
    "    bounds.append(adjusted_bound)\n",
    "    \n",
    "# Set up the optimization problem\n",
    "c = -optimised_data['MedianSpendPerOfferAmt'].values  # Objective function coefficients (negative for maximization)\n",
    "A = [[1] * len(data)]  # Constraint coefficients for the budget\n",
    "b = [30000]  # Total budget constraint\n",
    "\n",
    "# Solve the optimization problem\n",
    "res = linprog(c, A_ub=A, b_ub=b, bounds=bounds, method='highs')\n",
    "\n",
    "if res.success:\n",
    "    # Insert the \"OptimizedOfferAmount\" into the DataFrame\n",
    "    optimised_data['OptimizedOfferAmount'] = res.x\n",
    "    \n",
    "    # Calculate \"PredictedSpend\" based on the \"OptimizedOfferAmount\"\n",
    "    optimised_data['PredictedSpend'] = optimised_data['OptimizedOfferAmount'] * optimised_data['MedianSpendPerOfferAmt']\n",
    "    optimised_data['PredictedSpend'] = np.where(optimised_data['Predicted_Probability'] >= PROBABILITY_THRESHOLD,\n",
    "                                      optimised_data['PredictedSpend'], 0)\n",
    "\n",
    "    # Display the total expected spend and offer amount based on optimization\n",
    "    total_expected_spend = -res.fun\n",
    "    total_offer_amount = sum(res.x)\n",
    "    \n",
    "    print(\"Optimization successful!\")\n",
    "    print(f\"Total Expected Spend: £{total_expected_spend:.2f}\")\n",
    "    print(f\"Total Offer Amount: £{total_offer_amount:.2f}\")\n",
    "    print(f\"ROI: {(total_expected_spend/total_offer_amount):.2f}\")\n",
    "else:\n",
    "    print(\"Optimization failed:\", res.message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "c8d16d8a-2560-4b0d-b865-943207eedae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Actual Spend: £223698.54\n",
      "Total Actual Offered Amount: £110907.00\n",
      "ROI: 2.02\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Actual Spend: £{data['Spend'].sum():.2f}\")\n",
    "print(f\"Total Actual Offered Amount: £{data['OfferAmt'].sum():.2f}\")\n",
    "print(f\"ROI: {(data['Spend'].sum()/data['OfferAmt'].sum()):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d7ac2353-9f5f-4567-9ef0-6f1b1ed32e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = optimised_data[['PatronID', 'OfferAmt', 'Spend', 'RedeemedYN', 'Predicted_Probability', 'Predicted_RedeemedYN', 'Gradient', 'MedianSpendPerOfferAmt', 'TotalVisits','OptimizedOfferAmount', 'MaxOfferAmt', 'MaxSpendInTraining', 'PredictedSpend']]\n",
    "# result.to_csv(\"../result/nn_lr_coupon_strat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def15abd-81fc-4d11-b5de-05f7870276a6",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d7be50-618e-4020-a893-7ca3ed035534",
   "metadata": {},
   "source": [
    "The output ROI looks good, I am happy with my output. I will use this model to finish the problem. However:\n",
    "\n",
    "1) This model does not take into account the changing probability based on offers\n",
    "2) This is a linear problem solve, therefore it can't take into account the changing redepmtion probability if we tried\n",
    "3) This model is also too focused on the high earners. We need a more risk averse approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf4a6f-7226-4b35-9d7d-00dce80a3fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
